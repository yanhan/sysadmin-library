---
apiVersion: argoproj.io/v1alpha1
kind: Rollout
metadata:
  name: myapp
  namespace: default
spec:
  replicas: 5
  selector:
    matchLabels:
      app: myapp
  strategy:
    canary:
      # canary service must exist (it is defined in this manifest)
      canaryService: myapp-canary
      stableService: myapp
      trafficRouting:
        nginx:
          # stable ingress must exist (it is defined in this manifest)
          stableIngress: myapp
          additionalIngressAnnotations:
            canary-by-header: X-Canary
            canary-by-header-value: usecanary
      analysis:
        args:
          - name: service-name
            value: myapp-canary
        # This will start the analysisrun from the beginning of the
        # `steps` once a new rollout begins
        startingStep: 0
        templates:
          - templateName: myapp
      stableMetadata:
        labels:
          role: stable
      # Use ephemeral metadata to differentiate canary pods
      # https://argoproj.github.io/argo-rollouts/features/ephemeral-metadata/
      canaryMetadata:
        labels:
          role: canary
      steps:
        # NOTE: For real implementation, adjust the duration to higher values.
        - setWeight: 20
        - pause: {duration: 3m}
        - setWeight: 50
        - pause: {duration: 10m}
        - setWeight: 80
        - pause: {duration: 5m}
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
        - name: goserver
          image: localhost:6001/yanhan/goprom-argo-rollouts:0.1
          ports:
            - name: web
              containerPort: 3333
          readinessProbe:
            httpGet:
              path: /healthz
              port: web
            failureThreshold: 3
            successThreshold: 1
            periodSeconds: 5
            timeoutSeconds: 3
---
apiVersion: argoproj.io/v1alpha1
kind: AnalysisTemplate
metadata:
  name: myapp
  namespace: default
spec:
  args:
    - name: service-name
  metrics:
    - name: successrate
      # NOTE: For real implementations, increase interval to a higher value.
      # The lower value here is to allow analysisrun failures to show up
      # much faster
      # Adjust successCondition threshold as well.
      interval: 3m
      successCondition: result[0] >= 0.95
      failureLimit: 3
      provider:
        prometheus:
          # IMPT: Ensure this Promethteus address can be reached
          # Protip: set the spec.metrics[*].interval to 1m for faster iteration
          # and observation.
          # If metrics can be obtained, you will be able to observe it either
          # from `k argo rollouts get ROLLOUTNAME -w` (checkmark and red cross
          # with number will be displayed for success and failure respectively).
          # or using `kdes analysisrun` (metric value and success / fail sstatus
          # will be displayed)
          #
          # If you do not see any of the above, chances are the prometheus
          # cannot be reached (address may be incorrect)
          address: http://prometheus-k8s.monitoring.svc.cluster.local:9090
          # NOTE: For the query, please take into account of possible missing
          # metrics and use techniques to fill in default value (such as usage
          # of > 0 and OR) here. Otherwise, [NaN] will be returned and will
          # cause an error in the analysisrun
          query: |
            (
              (sum(rate(myapp_main_requests{service="{{args.service-name}}",role="canary",success="true"}[5m]) > 0) OR vector(0)) /
              sum(rate(myapp_main_requests_total{service="{{args.service-name}}",role="canary"}[5m]) > 0)
            ) OR vector(1)
---
apiVersion: v1
kind: Service
metadata:
  name: myapp
  namespace: default
  labels:
    # NOTE: labels are necessary on this Service object in order to pass
    # down these same labels to the k8s `endpoints` object.
    # This is to allow the ServiceMonitor below to use selector.matchLabels
    # to select the correct k8s `endpoints` object to scrape Prometheus
    # metrics
    app: myapp
spec:
  type: ClusterIP
  selector:
    app: myapp
  ports:
    - name: web
      port: 80
      targetPort: web
---
# Other than the name, everything in this canary service should be the
# same as the stable service
apiVersion: v1
kind: Service
metadata:
  name: myapp-canary
  namespace: default
  labels:
    app: myapp
spec:
  type: ClusterIP
  selector:
    app: myapp
  ports:
    - name: web
      port: 80
      targetPort: web
---
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: myapp
  namespace: default
spec:
  endpoints:
    - followRedirects: true
      path: /metrics
      port: web
  namespaceSelector:
    matchNames:
      - default
  # podTargetLabels transfers labels on k8s pods to the metrics
  # This allows us to use the `role` label select for metrics from
  # canary pods (canary pods have role=canary)
  podTargetLabels:
    - role
  selector:
    matchLabels:
      app: myapp
---
# Ingress for the stable replicaset
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: myapp
  namespace: default
spec:
  ingressClassName: nginx
  rules:
    - host: nginx.auto
      http:
        paths:
          - backend:
              service:
                name: myapp
                port:
                  name: web
            path: /
            pathType: Prefix
